---
title: "Huan-ang Gao (高焕昂)"
pubDate: 2025-07-28
---

![photo](about.assets/me.jpeg)

- First-year Ph. D. student @ CS & AIR, Tsinghua University
- Co-founder @ [Lumina-Embodied.AI](https://lumina-embodied.ai) Community




### Education

<div class="timeline-dark">
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Bachelor of Engineering</h3>
      <div class="timeline-meta">2020 - 2024 | Computer Science | Tsinghua University</div>
      <p><strong>GPA 3.98 / 4.00.</strong> Ranked <strong>#1</strong> out of 204 in the Department of CS.</p>
      <p>Proud to have received the highest distinction for undergraduates at <a href="https://air.tsinghua.edu.cn/info/1007/2133.htm">Tsinghua</a>.</p>
    </div>
  </div>
  
  
  <div class="timeline-item">
    <div class="timeline-dot in-progress"></div>
    <div class="timeline-content">
      <h3>Ph.D. Student</h3>
      <div class="timeline-meta">2024 - Present | Computer Science | Tsinghua University</div>
      <p> Advisor: Prof. <a href="https://air.tsinghua.edu.cn/en/info/1046/1188.htm">Ya-Qin Zhang</a>, Dean of Institute for AI Industry Research (AIR), THU.</p>
    </div>
  </div>

</div>

### Research Interests

Let's build the agents that transition humanity from *hands-off* interaction to a *minds-off* future! 
Most recently, I am working with [SIALab](https://air.tsinghua.edu.cn/en/info/1007/1886.htm) on building agents that set our mind free for daily tasks. 
Topics I am interested in:
- Multi-turn Reinforcement Learning
- Scalable Reinforcement Learning
- Evaluation of Capability Bottleneck in Agent Systems
- Self-evolution of Agent Systems



### Research Experience

<details open class="research-details">
<summary class="research-header research-green">Generative Simulation for Embodied AI</summary>

<div class="timeline-dark">
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Problem Identification</h3>
      <p>The development and iteration of autonomous driving and robotics policies are limited by the high costs, low efficiency, and safety risks of real-world testing. The rise of Generative AI offers a potential breakthrough by enabling high-fidelity, interactive, and editable simulation testing.</p>
    </div>
  </div>
  
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Technical Approach</h3>
      <p>My research focused on building "World Models" to drive simulation with generative methods. Technically, I explored two core directions: 1) <strong>High-fidelity Scene Reconstruction:</strong> Building "digital twins" of real scenes using technologies like NeRF or Gaussian splatting. 2) <strong>Controllable Content Generation:</strong> On the basis of reconstructed scenes, leveraging the generative priors of diffusion models to provide endless, controllable scene variations and edge cases.</p>
    </div>
  </div>
  
  <div class="timeline-item">
    <div class="timeline-dot in-progress"></div>
    <div class="timeline-content">
      <h3>Selected Publications</h3>
      <div class="timeline-meta">† indicates first or co-first author.</div>
      <ul>
        <li>†PartRM: Modeling Part-Level Dynamics with <strong>Large</strong> Cross-State <strong>Reconstruction Model</strong>, <em>CVPR 2025</em>.</li>
        <li>†Ctrl-U: Robust <strong>Conditional Image Generation</strong> Via Uncertainty-aware Reward Modeling, <em>ICLR 2025</em>.</li>
        <li>†SCP-Diff: Spatial-Categorical Joint Prior for <strong>Diffusion</strong> Based Semantic Image Synthesis, <em>ECCV 2024</em>.</li>
      </ul>
    </div>
  </div>
</div>

</details>

<details class="research-details">
<summary class="research-header research-orange">Data Efficient Scene Parsing</summary>

<div class="timeline-dark">
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Problem Identification</h3>
      <p>2D/3D perception is fundamental to embodied intelligence, but the extremely high cost of data annotation severely restricts the development of perception models.</p>
    </div>
  </div>
  
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Technical Approach</h3>
      <p>My early research focused on data-efficient perception learning algorithms, particularly <strong>semi-supervised learning</strong> and <strong>domain adaptation</strong>. In my first ICCV paper, DQS3D, I proposed a single-stage, densely-matched semi-supervised learning framework for 3D object detection, addressing the issue of insufficient training signals caused by sparse matching in previous methods. I also explored various levels of perception tasks such as self-supervised depth estimation, indoor layout estimation, and HD map generation, mastering task-oriented <strong>neural network and representation design methods</strong>.</p>
    </div>
  </div>
  
  <div class="timeline-item">
    <div class="timeline-dot finished"></div>
    <div class="timeline-content">
      <h3>Publications</h3>
      <div class="timeline-meta">† indicates first or co-first author.</div>
      <ul>
        <li>†DQS3D: Densely-matched Quantization-aware <strong>Semi-supervised</strong> 3D Detection, <em>ICCV 2023</em>.</li>
        <li>†From <strong>Semi-supervised</strong> to Omni-supervised Room Layout Estimation Using Point Clouds, <em>ICRA 2023</em>.</li>
        <li>†Training-Free <strong>Model Merging</strong> for Multi-target <strong>Domain Adaptation</strong>, <em>ECCV 2024</em>.</li>
      </ul>
    </div>
  </div>
</div>

</details>

### Services

<details open>
<summary><strong>Co-Founder</strong> @ <a href="https://lumina-embodied.ai">Lumina-Embodied.AI</a> (2025.4-Now)</summary>

- Building community for embodied AI research and applications
- Bridging academic research with industry implementations
- Focus on AI systems that learn through physical interaction

</details>

<details>
<summary><strong>Reviewer</strong> @ Academic Conferences & Journals</summary>

- CVPR (2025), ICCV (2025), WACV (2024), 3DV (2025), TPAMI
- NeurIPS (2025), ICLR (2025)
- ICRA (2025), IROS (2024, 2025), CoRL (2025)
- AAAI (2024), ICME (2025)

</details>

<details>
<summary>Teaching Assistant @ CS, THU</summary>

- (30240163) Software Engineering. Compulsory course in CS, THU. (23Spring, 23Fall, 24Spring, 24Fall, 25Spring, **25Fall**)
- (30240551) Digital Logic Experimentation. Compulsory course in CS, THU. (24Spring, 25Spring)
- (40240354) Computer Organization and Design. Compulsory course in CS, THU. (23Fall)
</details>

<details>
<summary>清华大学计算机系 科创辅导员 (2024.9-Now)</summary>

- Technical training & competition guidance for undergraduates
- Research & internship opportunity integration

</details>

<details>
<summary>清华大学计算机系 学生科协主席 (2023.5-2024.6)</summary>

- Built [homepage](https://net9.org/) & [documentation](https://docs.net9.org/)
- Organized [summer training camp](https://www.bilibili.com/video/BV1YmxMePE7x) for freshmen
- Launched [resource portal](https://stu.cs.tsinghua.edu.cn/resources/) for students

</details>





<style>
.timeline-dark {
  position: relative;
  padding-left: 32px;
  margin: 20px 0;
}

.timeline-dark::before {
  content: '';
  position: absolute;
  left: 8px;
  top: 8px;
  bottom: 0;
  width: 2px;
  background: #404040;
}

.timeline-item {
  position: relative;
  margin-bottom: 32px;
  padding-bottom: 8px;
}

.timeline-item:last-child .timeline-dark::before {
  display: none;
}

.timeline-dot {
  position: absolute;
  left: -28px;
  top: 2px;
  width: 16px;
  height: 16px;
  border-radius: 50%;
  box-sizing: border-box;
}

.timeline-dot.finished {
  background: linear-gradient(135deg, #3b82f6, #1d4ed8);
  border: 2px solid #3b82f6;
  box-shadow: 0 2px 8px rgba(59, 130, 246, 0.3);
}

.timeline-dot.in-progress {
  background: linear-gradient(135deg, #10b981, #059669);
  border: 2px solid #10b981;
  box-shadow: 0 2px 8px rgba(16, 185, 129, 0.3);
  animation: pulse 2s infinite;
}

.timeline-dot.waiting {
  background-color: transparent;
  border: 2px solid #6b7280;
  box-shadow: 0 2px 8px rgba(107, 114, 128, 0.2);
}

@keyframes pulse {
  0%, 100% {
    box-shadow: 0 2px 8px rgba(16, 185, 129, 0.3);
  }
  50% {
    box-shadow: 0 4px 12px rgba(16, 185, 129, 0.6);
  }
}

.timeline-content h3 {
  font-size: 18px;
  font-weight: 600;
  margin: 0 0px 8px 0;
  color: #ffffff !important; /* 强制白色 */
}

.timeline-meta {
  font-size: 14px;
  color: #cccccc !important; /* 浅灰色，但仍然清晰 */
  margin-bottom: 8px;
  font-weight: 500;
}

.research-details .timeline-content h3 {
  margin: 1rem 0 0rem 2rem;
}

.research-details .timeline-content .timeline-meta {
  margin: 0.1rem 0 0rem 2rem !important;
}

.research-details .timeline-content p {
  /* font-size: 18px; */
  color: #ffffff !important;
  margin: 0.5rem 0 0.5px 2rem !important;
  line-height: 1.6;
}

.research-details .timeline-content ul {
  /* font-size: 18px; */
  color: #ffffff !important;
  margin: 0.5rem 0 0.5px 0.5rem !important;
  line-height: 1.6;
  font-size: 14px;
}


.timeline-content p {
  font-size: 14px;
  color: #ffffff !important; /* 强制白色 */
  margin: 0 0 8px 0;
  line-height: 1.6;
}

.timeline-content p:last-child {
  margin-bottom: 0;
}

.timeline-content p:last-child {
  margin-bottom: 0;
}

/* 如果有加粗文字，确保也是白色 */
.timeline-content strong {
  color: #ffffff !important;
}

/* 适配亮色主题 */
@media (prefers-color-scheme: light) {
  .timeline-dark {
    padding-left: 28px;
  }
  
  .timeline-dot {
    left: -24px;
    width: 10px;
    height: 10px;
  }
  
  .timeline-content h3 {
    font-size: 16px;
  }
  
  .timeline-meta {
    font-size: 13px;
  }
  
  .timeline-content p {
    font-size: 13px;
  }
}

/* 个人照片样式 */
img[alt="photo"] {
  height: 200px !important;
  width: auto;
  object-fit: cover;
  border-radius: 8px;
  display: block;
  margin: 20px auto;
}

/* 折叠面板样式 */
details {
  /* border: 1px solid rgba(255, 255, 255, 0.1); */
  /* border-radius: 6px; */
  padding: 0.5rem !important;
  margin: 0 !important;
  background: rgba(255, 255, 255, 0.02);
}

details summary {
  padding: 0 !important;
  cursor: pointer;
  font-weight: 500;
  border-radius: 6px;
  transition: background-color 0.2s ease;
  margin: 0 !important;
  list-style: none;
}

details summary::-webkit-details-marker {
  display: none;
}

details summary::before {
  content: "▶";
  margin-right: 8px;
  transition: transform 0.2s ease;
  display: inline-block;
}

details[open] summary::before {
  transform: rotate(90deg);
}

details summary:hover {
  background: rgba(255, 255, 255, 0.05);
}

details div, details ul, details p {
  margin: 0 0 0 0 !important;
  padding: 0 0.1rem 0.1rem 0rem !important;
}

details ul {
  padding-left: 32px !important;
  padding-bottom: 0 !important;
  margin: 0 !important;
}

details li {
  margin: 4px 0 !important;
}

/* 适配亮色主题 */
@media (prefers-color-scheme: light) {
  .timeline-dark::before {
    background: #e1e1e1;
  }
  
  .timeline-content h3 {
    color: #262626 !important;
  }
  
  .timeline-meta {
    color: #595959 !important;
  }
  
  .timeline-content p {
    color: #595959 !important;
  }
  
  .timeline-content strong {
    color: #262626 !important;
  }
  
  .timeline-dot.waiting {
    border-color: #d9d9d9;
  }
  
  details {
    /* border: 1px solid rgba(0, 0, 0, 0.1); */
    /* background: rgba(0, 0, 0, 0.02); */
    padding: 0 !important;
    margin: 0 !important;
  }
  
  details summary:hover {
    padding: 0 !important;
    background: rgba(0, 0, 0, 0.05);
  }

  details ul {
    margin: 0 !important;
    padding-left: 32px !important;
    padding-bottom: 0 !important;
  }
}

/* 响应式设计 */
@media (max-width: 768px) {
  .timeline-dark {
    padding-left: 28px;
  }
  
  .timeline-dot {
    left: -24px;
    width: 14px;
    height: 14px;
  }
  
  .timeline-content h3 {
    font-size: 16px;
  }
  
  .timeline-meta {
    font-size: 13px;
  }
  
  .timeline-content p {
    font-size: 13px;
  }
}

/* 研究经历标题样式 */
.research-header {
  padding: 4px 20px !important;
  margin: 0 !important;
  border-radius: 16px !important;
  font-weight: 600 !important;
  color: white !important;
  cursor: pointer;
  transition: all 0.3s ease;
  display: block !important;
  font-size: 14px;
}

.research-green {
  background: linear-gradient(135deg, #4ade80, #22c55e) !important;
}

.research-orange {
  background: linear-gradient(135deg, #fb923c, #f97316) !important;
}

.research-header:hover {
  transform: translateY(-1px);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}

.research-header::before {
  content: "▶";
  margin-right: 8px;
}

/* 研究经历内容样式 */
details.research-details {
  margin: 0.5rem 0 !important;
  border: none !important;
  background: transparent !important;
}

details.research-details > div {
  padding: 0 !important;
  background: transparent !important;
  border: none !important;
  border-radius: 0 !important;
}

/* 确保details内的timeline与外部timeline样式一致 */
details.research-details .timeline-dark {
  position: relative;
  padding-left: 32px;
  margin: 20px 0;
}

details.research-details .timeline-dark::before {
  content: '';
  position: absolute;
  left: 8px;
  top: 8px;
  bottom: 0;
  width: 2px;
  background: #404040;
}

details.research-details .timeline-dot {
  position: absolute;
  left: 0px;
  top: 2px;
  width: 16px;
  height: 16px;
  border-radius: 50%;
  box-sizing: border-box;
  margin: 0;
  padding: 0;
  display: block;
}

details.research-details .timeline-dot.finished {
  background: linear-gradient(135deg, #3b82f6, #1d4ed8);
  border: 2px solid #3b82f6;
  box-shadow: 0 2px 8px rgba(59, 130, 246, 0.3);
}

details.research-details .timeline-dot.in-progress {
  background: linear-gradient(135deg, #10b981, #059669);
  border: 2px solid #10b981;
  box-shadow: 0 2px 8px rgba(16, 185, 129, 0.3);
  animation: pulse 2s infinite;
}

details.research-details .timeline-dot.waiting {
  background-color: transparent;
  border: 2px solid #6b7280;
  box-shadow: 0 2px 8px rgba(107, 114, 128, 0.2);
}

/* 适配亮色主题 */
@media (prefers-color-scheme: light) {
  details.research-details > div {
    background: transparent !important;
    border: none !important;
  }
  
  details.research-details .timeline-dark::before {
    background: #e1e1e1;
  }
}
</style>